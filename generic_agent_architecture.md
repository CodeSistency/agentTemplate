# Generic, Reusable AI Agent Architecture

This document outlines a generic, reusable architecture for building AI agents, leveraging modern frameworks like AG-UI, FastMCP, `mcp-use`, LangGraph, and LightRAG. The goal is to create a modular, scalable, and maintainable system.

## Guiding Principles

*   **Modularity**: Each component should be independent and replaceable.
*   **Reusability**: Components (especially tools and orchestration logic) should be easily reusable across different agents.
*   **Standardization**: Adhere to protocols like AG-UI for frontend-backend communication and MCP for agent-tool interaction.
*   **Scalability**: Design components to be scalable independently.
*   **Separation of Concerns**: Clearly delineate responsibilities between layers (presentation, gateway, orchestration, tooling).

## Architectural Layers

```mermaid
graph TD
    A[AG-UI Frontend] <--> B{Agent Gateway / BFF API};
    B <--> C{Agent Orchestration Layer (LangGraph + mcp-use + LLM)};
    C --> D[FastMCP Tool Servers];
    C --> E[LightRAG Knowledge Service];
    C --> A; %% For client-side actions / HITL responses

    subgraph Presentation Layer
        A
    end

    subgraph Backend Services
        B
        C
        D
        E
    end

    style A fill:#f9f,stroke:#333,stroke-width:2px
    style B fill:#ccf,stroke:#333,stroke-width:2px
    style C fill:#cfc,stroke:#333,stroke-width:2px
    style D fill:#ff9,stroke:#333,stroke-width:2px
    style E fill:#fca,stroke:#333,stroke-width:2px
```

### 1. Presentation Layer (Frontend)

*   **Technology**: **AG-UI** (e.g., `@copilotkit/react-core`, `@copilotkit/react-ui`).
*   **Responsibilities**:
    *   User interaction (chat, forms, dynamic UI elements).
    *   Rendering agent responses (text, structured data, UI generated by tools).
    *   Implementing client-side "actions" (`useCopilotAction`) callable by the backend.
    *   Handling AG-UI event streaming.
    *   Connecting to the Agent Gateway (`runtimeUrl`).

### 2. Agent Gateway / Backend-for-Frontend (BFF)

*   **Technology**: Lightweight web server (FastAPI, Flask, Next.js/Express API routes).
*   **Responsibilities**:
    *   Expose AG-UI compliant API endpoint(s).
    *   Handle authentication, authorization, and session management.
    *   Act as a bridge, routing requests to the Agent Orchestration Layer and streaming responses back.

### 3. Agent Orchestration Layer (The "Brain")

*   **Technology**: **LangGraph** (Python) for core logic, **`mcp-use`** (Python) for MCP tool consumption, integrated with LLMs (via LangChain or direct SDKs).
*   **Responsibilities**:
    *   Define agent control flow (StateGraphs in LangGraph).
    *   Manage conversational state (compatible with AG-UI, e.g., `CopilotKitState`).
    *   Interface with LLMs for reasoning and decision-making.
    *   Consume tools from FastMCP servers via `mcp-use`.
    *   Query LightRAG for knowledge retrieval.
    *   Invoke client-side actions on the AG-UI frontend.
    *   Implement Human-in-the-Loop (HITL) patterns.

### 4. Tooling & Knowledge Layer (Backend Services)

*   **A. FastMCP Tool Servers**:
    *   **Technology**: **FastMCP** (Python).
    *   **Responsibilities**: Expose discrete, reusable functionalities as MCP tools (e.g., calculations, API integrations, data processing).
*   **B. LightRAG Knowledge Service**:
    *   **Technology**: **LightRAG**.
    *   **Responsibilities**: Document ingestion, embedding, indexing, and providing a retrieval API for semantic search.
*   **C. Other Custom Backend Services**: Databases, legacy systems, etc. (preferably exposed via FastMCP tools).

## Proposed Folder Structure

```
/project-root
├── frontend/                     # AG-UI based frontend application (e.g., Next.js, React)
│   ├── src/
│   │   ├── app/                  # Next.js app router or similar
│   │   │   └── api/
│   │   │       └── copilotkit/   # AG-UI Agent Gateway endpoint (BFF)
│   │   │           └── route.ts  # Example for Next.js
│   │   ├── components/           # Reusable UI components
│   │   ├── agents/               # Client-side agent configurations or helpers
│   │   └── ...                   # Other frontend assets, styles, utils
│   └── public/
├── backend/
│   ├── orchestrators/            # LangGraph agent orchestrators
│   │   └── specific_agent_orchestrator/
│   │       ├── graph.py          # LangGraph definition
│   │       ├── state.py          # Agent state models
│   │       └── prompts.py        # Prompts for the agent
│   ├── mcp_servers/              # FastMCP tool servers
│   │   └── specific_tool_server/
│   │       ├── server.py         # FastMCP server definition
│   │       └── tools/
│   │           └── some_tool.py
│   ├── knowledge_services/       # LightRAG or other knowledge services
│   │   └── lightrag_service/
│   │       └── ...               # LightRAG setup and API exposure
│   ├── core_libs/                # Shared Python libraries for backend services
│   │   └── utils.py
│   └── main_gateway.py           # Optional: A central Python AG-UI gateway if not using Next.js BFF
├── docs/                         # Project documentation
├── scripts/                      # Utility scripts (deployment, testing)
├── tests/
│   ├── frontend/
│   └── backend/
├── .env                          # Environment variables
├── requirements.txt              # Python backend dependencies
├── package.json                  # Frontend dependencies
└── README.md
```

**Meaning of Key Folders:**

*   `frontend/`: All client-facing code. The `api/copilotkit` subfolder is a common pattern for implementing the AG-UI BFF within a Next.js app.
*   `backend/`: All server-side logic and services.
    *   `orchestrators/`: Houses the core logic for different AI agents, built with LangGraph.
    *   `mcp_servers/`: Contains various FastMCP servers, each providing a set of related tools.
    *   `knowledge_services/`: For RAG implementations like LightRAG.
    *   `core_libs/`: Shared Python utilities for backend components.
*   `docs/`: Documentation for the project, architecture, APIs, etc.
*   `scripts/`: Helper scripts for development, deployment, etc.
*   `tests/`: Unit, integration, and end-to-end tests.

## Mini Example: "Echo & UpperCase" Agent

This example demonstrates a very simple agent that can echo messages or convert them to uppercase using a FastMCP tool.

**1. Frontend (`frontend/src/app/page.tsx`) - Conceptual AG-UI**

```tsx
// frontend/src/app/page.tsx (Conceptual - using CopilotKit)
"use client";
import { CopilotKit } from "@copilotkit/react-core";
import { CopilotChat } from "@copilotkit/react-ui";
import "@copilotkit/react-ui/styles.css";

export default function HomePage() {
  return (
    <CopilotKit runtimeUrl="/api/copilotkit"> {/* Points to our BFF */}
      <CopilotChat 
        labels={{
          title: "Echo & UpperCase Agent",
          initial: "Hi! I can echo your messages or make them uppercase. Try 'echo hello' or 'upper hello world'."
        }}
        agent="echo_upper_agent" // Identifies which orchestrator to use
      />
    </CopilotKit>
  );
}
```

**2. Agent Gateway / BFF (`frontend/src/app/api/copilotkit/route.ts`) - Conceptual Next.js**

```typescript
// frontend/src/app/api/copilotkit/route.ts (Conceptual Next.js API route)
// This would typically forward requests to a Python backend running LangGraph.
// For a direct Python AG-UI server, this BFF layer might be simpler or part of the Python service.

import { CopilotRuntime } from "@copilotkit/runtime";

export async function POST(req: Request): Promise<Response> {
  const copilotKit = new CopilotRuntime();
  // This example is simplified. In a real scenario, this endpoint would
  // proxy requests to your Python LangGraph agent service.
  // For instance, by making an HTTP request to the Python service that
  // implements the AG-UI server protocol for the specific agent.
  const agentId = req.headers.get("X-CopilotKit-Agent-Id") || "echo_upper_agent";
  
  // Placeholder: In reality, you'd call your Python backend here.
  // e.g., fetch(`http://localhost:8000/agents/${agentId}`, { method: "POST", body: req.body ... })
  // The Python backend would then handle the AG-UI protocol.
  
  // For this conceptual example, we'll assume a direct handling (not realistic for LangGraph in Python from here)
  return copilotKit.response(req, async (event) => {
    // This part is illustrative of what the Python backend would do.
    if (event.type === "event" && event.name === "copilotkitRequest") {
        // Forward to Python LangGraph service
        console.log("Forwarding to Python backend with payload:", event.payload);
        // The Python service would then stream back AG-UI events.
    }
  });
}

// Note: A more robust solution for Python backends is to have the Python service
// directly implement the AG-UI server capabilities (e.g., using FastAPI and a Python AG-UI server library if available,
// or by manually implementing the AG-UI SSE protocol).
```

**3. FastMCP Tool Server (`backend/mcp_servers/string_tools/server.py`)**

```python
# backend/mcp_servers/string_tools/server.py
from fastmcp import FastMCP

mcp = FastMCP(name="StringTools")

@mcp.tool()
def to_upper_case(text: str) -> str:
    """Converts text to uppercase."""
    return text.upper()

if __name__ == "__main__":
    # To run: python backend/mcp_servers/string_tools/server.py
    # By default, runs on http://localhost:8000 if mcp-use is configured for HTTP
    # or can be run as a subprocess by mcp-use.
    mcp.run()
```

**4. Agent Orchestrator (`backend/orchestrators/echo_upper_orchestrator/graph.py`)**

```python
# backend/orchestrators/echo_upper_orchestrator/graph.py
import os
from typing import TypedDict, Annotated, Sequence
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END, START
from langgraph.checkpoint.memory import MemorySaver

from mcp_use import MCPClient # For calling FastMCP tools

# --- MCP Client Setup ---
# This config tells mcp-use how to start the string_tools server if not already running via HTTP.
# If string_tools server is run independently (e.g., `python server.py` and exposed on a port),
# mcp-use can connect via URL instead of command.
mcp_config = {
    "mcpServers": {
        "string_tools": {
            "command": "python3", # Use python3 based on memory
            "args": [os.path.join(os.path.dirname(__file__), "..", "..", "mcp_servers", "string_tools", "server.py")],
            "#url": "http://localhost:8001" # Example if running independently
        }
    }
}
# Initialize MCPClient. In a real app, this might be a singleton or managed.
mcp_client = MCPClient.from_dict(mcp_config)

# --- LangGraph State Definition ---
class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], lambda x, y: x + y]
    # Add other state variables as needed

# --- LangGraph Nodes ---
def call_llm_or_tools(state: AgentState):
    current_messages = state["messages"]
    last_message_text = current_messages[-1].content.lower()
    response_text = ""

    if last_message_text.startswith("echo "):
        response_text = last_message_text[5:] # Echo back
    elif last_message_text.startswith("upper "):
        text_to_upper = last_message_text[6:]
        try:
            # Call the FastMCP tool via mcp-use
            # The first argument to call_tool is "server_name.tool_name"
            tool_result = mcp_client.call_tool("string_tools.to_upper_case", {"text": text_to_upper})
            response_text = tool_result.text
        except Exception as e:
            response_text = f"Error calling uppercase tool: {e}"
    else:
        # Basic LLM fallback (optional, could just be specific commands)
        # For simplicity, we'll just give a default response here.
        # In a real agent, you'd use ChatOpenAI or similar.
        response_text = "Sorry, I can only 'echo <text>' or 'upper <text>'."

    return {"messages": [AIMessage(content=response_text)]}

# --- LangGraph Definition ---
workflow = StateGraph(AgentState)
workflow.add_node("action_node", call_llm_or_tools)
workflow.add_edge(START, "action_node")
workflow.add_edge("action_node", END)

# --- Compile Graph ---
# This is the agent graph that the AG-UI server (Python part) would invoke.
echo_upper_agent_graph = workflow.compile(checkpointer=MemorySaver())

# --- AG-UI Server (Conceptual - to be run by your Python AG-UI Gateway) ---
# To make this runnable with AG-UI, you'd need a Python server (e.g., FastAPI)
# that implements the AG-UI protocol (handles SSE, message formats) and invokes
# this `echo_upper_agent_graph.astream_events(...)` for each user session/request.

# Example of how it might be invoked (highly simplified):
async def handle_ag_ui_request(payload):
    # 'payload' would contain user message, thread_id, etc.
    # Map payload to initial AgentState
    config = {"configurable": {"thread_id": payload.get("threadId", "default")}} # Example
    initial_state = {"messages": [HumanMessage(content=payload["message"]["content"])]}
    
    async for event in echo_upper_agent_graph.astream_events(initial_state, config=config, version="v2"):
        # Map LangGraph events to AG-UI SSE events and stream them back
        # This is the part a Python AG-UI server library would handle.
        print(f"AGENT EVENT: {event['event']}", event['data'])
        if event['event'] == 'on_chat_model_stream' and event['data'].get('chunk'):
            # yield AG-UI text_message_content event
            pass
        if event['event'] == 'on_chain_end' and event['data'].get('output'):
            # This is where the final AIMessage is usually found in 'output['messages'][-1]'
            # yield AG-UI text_message_end event
            pass

# To run this example (conceptually):
# 1. Start the FastMCP server: `python3 backend/mcp_servers/string_tools/server.py`
#    (or let mcp-use start it as a subprocess if 'command' is used in mcp_config)
# 2. Start your AG-UI Python Gateway that uses `echo_upper_agent_graph`.
# 3. Start the frontend: `npm run dev` (or similar).
```

**Running the Mini Example (Conceptual Steps):**

1.  **Start FastMCP Tool Server**: If you're not relying on `mcp-use` to start it via `command`:
    `python3 backend/mcp_servers/string_tools/server.py`
2.  **Start Agent Orchestrator Service**: This involves creating a Python web server (e.g., using FastAPI) that:
    *   Implements the AG-UI server-side protocol (handles SSE connections, message formats).
    *   Receives requests from your BFF (or directly from the AG-UI frontend if the BFF is minimal).
    *   For each request, invokes the compiled LangGraph: `echo_upper_agent_graph.astream_events(...)`.
    *   Streams the LangGraph events back to the client, formatted as AG-UI events.
3.  **Start Frontend**: Navigate to `frontend/` and run `npm run dev` (or your project's equivalent).
4.  **Interact**: Open the frontend in your browser. You should be able to send messages like "echo test" or "upper example" to the agent.

This mini-example simplifies many aspects (especially the AG-UI Python server part and BFF implementation) but illustrates the core interaction between the layers using the proposed frameworks.
