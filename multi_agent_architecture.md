# Multi-Agent AI Architecture with Advanced Knowledge Management

This document outlines a multi-agent AI architecture, building upon a generic, reusable foundation. It leverages modern frameworks like AG-UI, FastMCP, `langchain-mcp-adapters`, LangGraph, and LightRAG (including its Knowledge Graph capabilities) to create a modular, scalable, and maintainable system capable of orchestrating multiple specialized agents and managing diverse knowledge sources.

## Guiding Principles

*   **Modularity**: Each component should be independent and replaceable.
*   **Reusability**: Components (especially tools, knowledge sources, and specialized agents) should be easily reusable.
*   **Standardization**: Adhere to protocols like AG-UI for frontend-backend communication and MCP for agent-tool interaction.
*   **Scalability**: Design components to be scalable independently.
*   **Separation of Concerns**: Clearly delineate responsibilities between layers.
*   **Agent Specialization and Orchestration**: Employ specialized agents for specific tasks and a master orchestrator to route requests and manage interactions.
*   **Dynamic Knowledge Integration**: Support both persistent general knowledge and transient, session-specific contextual knowledge.

## Architectural Layers

```mermaid
graph TD
    A[AG-UI Frontend] <--> B{Agent Gateway / BFF API};
    B <--> C_Master{Master Agent Orchestrator (LangGraph)};
    C_Master --> SA1{Specialized Agent A (LangGraph)};
    C_Master --> SA2{Specialized Agent B (LangGraph)};
    C_Master --> SAN{...};
    SA1 --> D[FastMCP Tool Servers];
    SA2 --> D;
    SAN --> D;
    SA1 --> E_KG[LightRAG Knowledge Service + KG];
    SA2 --> E_KG;
    SAN --> E_KG;
    C_Master --> E_KG; 
    C_Master --> A; %% For client-side actions / HITL responses from Master
    SA1 --> A; %% For client-side actions / HITL responses from Specialized Agent

    subgraph Presentation Layer
        A
    end

    subgraph Backend Services
        B
        subgraph Agent Orchestration Layer
            C_Master
            SA1
            SA2
            SAN
        end
        D
        E_KG
    end

    style A fill:#f9f,stroke:#333,stroke-width:2px
    style B fill:#ccf,stroke:#333,stroke-width:2px
    style C_Master fill:#afa,stroke:#333,stroke-width:2px
    style SA1 fill:#cfc,stroke:#333,stroke-width:2px
    style SA2 fill:#cfc,stroke:#333,stroke-width:2px
    style SAN fill:#cfc,stroke:#333,stroke-width:2px
    style D fill:#ff9,stroke:#333,stroke-width:2px
    style E_KG fill:#fca,stroke:#333,stroke-width:2px
```

### 1. Presentation Layer (Frontend)

*   **Technology**: **AG-UI** (e.g., `@copilotkit/react-core`, `@copilotkit/react-ui`).
*   **Responsibilities**:
    *   User interaction (chat, forms, dynamic UI elements).
    *   Rendering agent responses (text, structured data, UI generated by tools).
    *   Implementing client-side "actions" (`useCopilotAction`) callable by the backend.
    *   Handling AG-UI event streaming.
    *   Connecting to the Agent Gateway (`runtimeUrl`).
    *   Providing UI elements for selecting the desired LLM (e.g., OpenAI, Gemini, local Ollama models), potentially configurable per agent or globally.
    *   Providing UI elements for selecting the active agent (e.g., "Customer Support Agent", "Data Analyst Agent") or a "Multi-Agent Orchestrator" mode that automatically routes tasks.
    *   Displaying conversation history and offering controls for chat session management (e.g., initiating a new chat, clearing/restarting the current chat), managing `threadId`s.
    *   Providing UI for submitting documents or text for in-chat contextual knowledge grounding (session-specific knowledge) to be used by the active agent(s).

### 2. Agent Gateway / Backend-for-Frontend (BFF)

*   **Technology**: Lightweight web server (FastAPI, Flask, Next.js/Express API routes).
*   **Responsibilities**:
    *   Expose AG-UI compliant API endpoint(s).
    *   Handle authentication, authorization, and session management.
    *   Act as a bridge, routing requests to the Agent Orchestration Layer and streaming responses back.
    *   Receiving the selected LLM preference from the frontend and passing it to the Agent Orchestration Layer.
    *   Receiving the selected agent or "Multi-Agent Orchestrator" mode from the frontend and passing this to the Agent Orchestration Layer.
    *   Interpreting session management cues from the frontend (e.g., requests for a new chat) to ensure appropriate `threadId` handling.
    *   Handling uploads or submissions of documents/text for in-chat knowledge, validating them, and passing them to the LightRAG service for temporary processing and indexing associated with the current session/thread.

### 3. Agent Orchestration Layer (The "Brain")

This layer is composed of a Master Agent Orchestrator and multiple Specialized Agent Orchestrators.

*   **A. Master Agent Orchestrator**:
    *   **Technology**: **LangGraph** (Python), integrated with LLMs.
    *   **Responsibilities**:
        *   Acts as the primary entry point for user requests when in "Multi-Agent" mode.
        *   Analyzes incoming user requests and determines the most appropriate Specialized Agent (or sequence of agents) to handle the task. This involves LLM-based routing, intent recognition, or rule-based dispatching.
        *   Manages the overall conversation state if multiple agents are involved in fulfilling a single complex request.
        *   Delegates tasks to Specialized Agents and potentially aggregates their responses.
        *   Handles conversational history at a high level, passing relevant context to specialized agents.
        *   Interfaces with the selected LLM for routing decisions and high-level reasoning.

*   **B. Specialized Agent Orchestrators**:
    *   **Technology**: Each is typically a **LangGraph** (Python) instance, using **`langchain-mcp-adapters`** for MCP tool consumption, integrated with LLMs.
    *   **Responsibilities (per specialized agent)**:
        *   Handles specific types of tasks or domains (e.g., customer service, data analysis, code generation).
        *   Defines its own control flow (StateGraph), manages its specific conversational state, and uses its own set of prompts.
        *   Consumes tools from FastMCP servers relevant to its specialization.
        *   Queries the LightRAG Knowledge Service for both general knowledge and any session-specific knowledge provided by the user.
        *   Can invoke client-side actions on the AG-UI frontend.
        *   Can implement Human-in-the-Loop (HITL) patterns for its specific tasks.

*   **General Responsibilities for the Entire Orchestration Layer**:
    *   Dynamically initializing or selecting the appropriate LLM client based on global or agent-specific preferences.
    *   Reliably managing chat history and state using LangGraph's checkpointer mechanism (e.g., `MemorySaver`), keyed by `thread_id`. Each specialized agent might have its own view or segment of the history, coordinated by the Master Orchestrator or `thread_id`.
    *   Supporting the creation of new chat sessions by operating on new `thread_id`s.
    *   Facilitating the use of knowledge from LightRAG, including its knowledge graph features, by providing context or direct query capabilities to the LLMs and tools.

### 4. Tooling & Knowledge Layer (Backend Services)

*   **A. FastMCP Tool Servers**:
    *   **Technology**: **FastMCP** (Python).
    *   **Responsibilities**: Expose discrete, reusable functionalities as MCP tools. These tools are consumed by Specialized Agents.

*   **B. LightRAG Knowledge Service**:
    *   **Technology**: **LightRAG** (Python).
    *   **Responsibilities**:
        *   **General Knowledge Management**:
            *   Ingestion of diverse document types (text, PDF, etc.) for building a persistent, general knowledge base.
            *   Embedding, indexing, and building/maintaining a knowledge graph (KG) from this general knowledge corpus using LightRAG's built-in capabilities.
            *   Providing APIs for semantic search, graph traversal, and contextualized retrieval over the general knowledge.
        *   **Session-Specific (In-Chat) Knowledge Management**:
            *   Receiving documents/text provided by the user during a chat session via the Agent Gateway.
            *   Temporarily processing, embedding, and indexing this session-specific content. This might involve creating a temporary, isolated LightRAG index or a special section within the main index tagged by `session_id`/`thread_id`.
            *   Making this session-specific knowledge available for retrieval by the active agent(s) for the duration of the session.
            *   Managing the lifecycle of session-specific knowledge (e.g., automatic cleanup after session ends, TTL, or explicit user command).
        *   **Unified Retrieval**: Offering retrieval capabilities that can seamlessly query across general knowledge, session-specific knowledge, and the knowledge graph, or prioritize them based on context.

*   **C. Other Custom Backend Services**: Databases, legacy systems, etc. (preferably exposed via FastMCP tools).

## Proposed Folder Structure

```
/project-root
├── frontend/                     # AG-UI based frontend application
│   └── ... (similar to generic architecture)
├── backend/
│   ├── orchestrators/            # LangGraph agent orchestrators
│   │   ├── master_orchestrator/  # Master agent for routing
│   │   │   ├── graph.py
│   │   │   ├── state.py
│   │   │   └── prompts.py
│   │   └── specialized_agents/   # Directory for all specialized agents
│   │       ├── agent_A_orchestrator/
│   │       │   ├── graph.py
│   │       │   ├── state.py
│   │       │   └── prompts.py
│   │       └── agent_B_orchestrator/
│   │           └── ...
│   ├── mcp_servers/              # FastMCP tool servers
│   │   └── ... (similar to generic architecture)
│   ├── knowledge_services/       # LightRAG and other knowledge services
│   │   └── lightrag_instance/
│   │       ├── config.py         # LightRAG configurations (storage, models)
│   │       ├── ingestion_pipelines/ # Scripts for general knowledge ingestion
│   │       └── service.py        # API wrapper for LightRAG functionalities
│   ├── core_libs/                # Shared Python libraries
│   └── main_gateway.py           # Central Python AG-UI gateway
├── docs/
├── scripts/
│   └── knowledge_ingestion/      # Scripts for populating general knowledge
├── tests/
├── .env
├── requirements.txt
├── package.json
└── README.md
```

**Meaning of Key Folder Changes:**

*   `backend/orchestrators/master_orchestrator/`: Contains the logic for the master agent that routes to specialized agents.
*   `backend/orchestrators/specialized_agents/`: Each sub-folder here represents a distinct, focused agent.
*   `backend/knowledge_services/lightrag_instance/`: Dedicated to LightRAG setup, including how it handles both general and session-specific data, and its KG.
*   `scripts/knowledge_ingestion/`: For populating the general knowledge base in LightRAG.

## Mini Example Scenarios

**Scenario 1: Master Orchestrator Routing**

1.  **User Input**: "Can you summarize sales_report.pdf and then tell me the weather in London?"
2.  **Frontend**: User selects "Multi-Agent Orchestrator" mode. LLM selection is global (e.g., GPT-4).
3.  **Agent Gateway**: Relays the request and agent mode to the Master Orchestrator.
4.  **Master Orchestrator**:
    *   Receives "Can you summarize sales_report.pdf and then tell me the weather in London?".
    *   Identifies two sub-tasks: document summarization and weather query.
    *   Routes "summarize sales_report.pdf" to a "DocumentAnalysisAgent" (a specialized agent).
    *   The "DocumentAnalysisAgent" might use a LightRAG tool to process `sales_report.pdf` (if provided in-chat or already ingested) and an LLM to summarize.
    *   Once summarization is done, the Master Orchestrator routes "tell me the weather in London" to a "GeneralQueryAgent" or an agent with a weather tool.
    *   The "GeneralQueryAgent" uses a weather FastMCP tool.
    *   The Master Orchestrator combines responses and presents them to the user.

**Scenario 2: In-Chat Knowledge Grounding**

1.  **User Action**: User uploads `project_specs.docx` via the frontend UI.
2.  **Frontend**: Sends the document to the Agent Gateway, indicating it's for the current session. User is interacting with "ProjectQA_Agent".
3.  **Agent Gateway**: Passes `project_specs.docx` to the LightRAG service, tagging it with the current `thread_id`.
4.  **LightRAG Service**: Temporarily ingests, embeds, and indexes `project_specs.docx`. Its content is now searchable for this session.
5.  **User Input**: "What is the deadline mentioned in the document?"
6.  **ProjectQA_Agent (Specialized Agent)**:
    *   Receives the query.
    *   Its LangGraph definition includes steps to query LightRAG.
    *   The query to LightRAG is scoped to include both general project knowledge AND the session-specific knowledge from `project_specs.docx` associated with the `thread_id`.
    *   Retrieves relevant chunks from `project_specs.docx`.
    *   Uses its LLM to answer the question based on the retrieved context.
7.  **Frontend**: Displays the answer.
8.  **Post-Session**: The temporary index for `project_specs.docx` might be cleared by LightRAG based on its policy.

## Knowledge Management Details

*   **General Knowledge Ingestion**:
    *   Typically an offline or batch process managed via scripts in `scripts/knowledge_ingestion/`.
    *   Populates the main LightRAG vector store and knowledge graph.
    *   This knowledge is persistent and available broadly (respecting access controls if any).
*   **Session-Specific Knowledge**:
    *   Handled dynamically during a chat.
    *   LightRAG needs to be configured or wrapped in a service that can create temporary, isolated, or specially tagged indexes for this data.
    *   The retrieval process in specialized agents must be aware of the `thread_id` or `session_id` to query the correct combination of general and session-specific knowledge.
    *   Consider data privacy and cleanup for session-specific data.
*   **Knowledge Graph Usage**:
    *   LightRAG's KG capabilities can be used by agents to answer questions requiring understanding of relationships, multi-hop queries, or exploration of connected data points.
    *   Specialized agents might have tools or prompt strategies to formulate KG queries (e.g., Cypher if LightRAG exposes it, or natural language queries that LightRAG translates to KG operations).

This multi-agent architecture provides a robust framework for building sophisticated AI applications that can leverage multiple specialized AI skills and diverse, dynamically updated knowledge sources.
